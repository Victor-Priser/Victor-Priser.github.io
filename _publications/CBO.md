---
title: "Consensus-Based Optimization Beyond Finite-Time Analysis"
collection: preprint
#category: manuscripts
permalink: /publication/CBO
#excerpt: 'This paper is about the number 3. The number 4 is left for future work.'
date: 2025-01-01
venue: 'preprint'
#slidesurl: 'https://academicpages.github.io/files/slides3.pdf'
paperurl: 'https://arxiv.org/pdf/2509.12907'
citation: 'Priser V., Dragomir R.-A., Bianchi P.'
---

We analyze a zeroth-order particle algorithm for the global optimization of a non-convex function, focusing on a variant of Consensus-Based Optimization (CBO) with small but fixed noise intensity. 

Unlike most previous studies, which are restricted to finite horizons, we investigate its long-time behavior with fixed parameters. In the mean-field limit, a quantitative Laplace principle shows exponential convergence to a neighborhood of the minimizer $x^\ast$. 

For a finite number of particles, a block-wise analysis yields explicit error bounds: individual particles achieve long-time consistency near $x^\ast$, and the global best particle converges to $x^\ast$. 

The proof technique combines a quantitative Laplace principle with block-wise control of Wasserstein distances, avoiding the exponential blow-up typical of Gr√∂nwall-based estimates.

